{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet baseline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a297d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from dataset import HDF5Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f347b9",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b807c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4w/dhmdb97x63lfq799n_46pwc80000gn/T/ipykernel_22711/2231450438.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(\"../train-metadata.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata = pd.read_csv(\"../train-metadata.csv\")\n",
    "hdf5 = h5py.File(\"../train-image.hdf5\", \"r\")\n",
    "\n",
    "# Sample balanced malignant and benign\n",
    "malignant_ids = metadata[metadata[\"target\"] == 1].sample(n=393, random_state=42)[\"isic_id\"].tolist()\n",
    "benign_ids = metadata[metadata[\"target\"] == 0].sample(n=393, random_state=42)[\"isic_id\"].tolist()\n",
    "\n",
    "def load_images(ids):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_id in ids:\n",
    "        image = hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        images.append(image)\n",
    "        labels.append(1 if image_id in malignant_ids else 0)\n",
    "    return images, labels\n",
    "\n",
    "images_mal, labels_mal = load_images(malignant_ids)\n",
    "images_ben, labels_ben = load_images(benign_ids)\n",
    "\n",
    "# Combine and split\n",
    "all_images = np.array(images_mal + images_ben)\n",
    "all_labels = np.array(labels_mal + labels_ben)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_images, all_labels, test_size=0.1, stratify=all_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff20948",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee22607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54523866",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = DenseNet121_Weights.DEFAULT\n",
    "transform = weights.transforms()\n",
    "model = densenet121(weights=weights)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce58d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=transform)\n",
    "val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce21396",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "train_losses, val_losses = [], []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []\n",
    "# partial AUC, used to compare between models \n",
    "# v_gt = abs(np.asarray(Y_test) - 1)\n",
    "# v_pred = np.array([1.0 - x for x in Y_probs])\n",
    "# max_fpr = abs(1 - min_tpr)\n",
    "# partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=0.8)\n",
    "# partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)  # [B, 1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_auc = roc_auc_score(targets, preds)\n",
    "    \n",
    "    # Threshold predictions at 0.5\n",
    "    pred_labels = (np.array(preds) >= 0.5).astype(int)\n",
    "    true_labels = np.array(targets).astype(int)\n",
    "\n",
    "    val_acc = accuracy_score(true_labels, pred_labels)\n",
    "    val_precision = precision_score(true_labels, pred_labels)\n",
    "    val_recall = recall_score(true_labels, pred_labels)\n",
    "    val_f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Acc = {val_acc:.4f}, Precision = {val_precision:.4f}, Recall = {val_recall:.4f}, F1 = {val_f1:.4f}\") \n",
    "    val_accuracies.append(val_acc)\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "    val_f1s.append(val_f1)\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_losses[-1],\n",
    "        'val_loss': val_losses[-1],\n",
    "        'val_auc': val_auc\n",
    "    }, f\"checkpoints/DenseNet_epoch_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"DenseNet Training Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"DenseNet_loss_curve.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
