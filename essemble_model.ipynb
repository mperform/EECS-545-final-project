{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c96576d",
   "metadata": {},
   "source": [
    "# Assemble Model using DenseNet, EfficientNet, ResNet50, XGBoost, Light GBM, and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0552969-dff4-4a3e-9bb9-361925f9e4c4",
   "metadata": {},
   "source": [
    "## Here's datasets you will need\n",
    "- train-image.hdf5\n",
    "- train-metadata.csv\n",
    "- augmented_data.hdf5\n",
    "- augmented_metadata.csv\n",
    "- isic_image.hdf5\n",
    "- isic_metadata.csv\n",
    "- test-image.hdf5\n",
    "- test-metadata.csv\n",
    "## Here's the models/paths you need to run without training the CNN model\n",
    "- DenseNet121_checkpoints/DenseNet121_epoch_20.pth\n",
    "- EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\n",
    "- ResNet50_checkpoints/ResNet50_epoch_20.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb04e90",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dd2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from dataset import HDF5Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from isic_metric import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d49bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863765d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0a64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "metadata = []\n",
    "malignant_count = 0\n",
    "benign_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a898a1d",
   "metadata": {},
   "source": [
    "### First, load all data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7f05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_hdf5_path = 'train-image.hdf5'\n",
    "original_train_metadata_path = 'train-metadata.csv'\n",
    "original_train_metadata = pd.read_csv(original_train_metadata_path,low_memory=False)   \n",
    "original_train_hdf5 = h5py.File(original_train_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31be5557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401059/401059 [06:39<00:00, 1003.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 401059 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(original_train_metadata))):\n",
    "    if original_train_metadata.iloc[i]['target'] == 0: \n",
    "        labels.append(0)\n",
    "        benign_count += 1\n",
    "    else:\n",
    "        labels.append(1)\n",
    "        malignant_count += 1\n",
    "    image_id = original_train_metadata.iloc[i]['isic_id']\n",
    "    image = original_train_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    images.append(image)\n",
    "    metadata.append(original_train_metadata.iloc[i])\n",
    "print(f'Loaded {len(images)} images')\n",
    "# original_train_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989ac7f",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3675c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into 240635 training, 60159 validation, and 100265 testing samples.\n"
     ]
    }
   ],
   "source": [
    "# 60% training, 15% validation, 25% testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.625, random_state=42)  # 0.625 * 0.4 = 0.25\n",
    "\n",
    "# split metadata\n",
    "metadata_train, metadata_temp = train_test_split(metadata, test_size=0.4, random_state=42)\n",
    "metadata_val, metadata_test = train_test_split(metadata_temp, test_size=0.625, random_state=42)  # 0.625 * 0.4 = 0.25\n",
    "print(f'Data split into {len(X_train)} training, {len(X_val)} validation, and {len(X_test)} testing samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26e478",
   "metadata": {},
   "source": [
    "## Add Augmented malignant images to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e157a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_malignant_hdf5_path = 'augmented_data.hdf5'\n",
    "augmented_malignant_metadata_path = 'augmented_metadata.csv'\n",
    "augmented_malignant_metadata = pd.read_csv(augmented_malignant_metadata_path,low_memory=False)\n",
    "augmented_malignant_hdf5 = h5py.File(augmented_malignant_hdf5_path, 'r')\n",
    "n_augmentations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d51fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1965/1965 [00:02<00:00, 724.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded augmented malignant images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(augmented_malignant_metadata))):\n",
    "    image_id = f\"{augmented_malignant_metadata.iloc[i]['isic_id']}\"\n",
    "    image = augmented_malignant_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    X_train.append(image)\n",
    "    y_train.append(1)\n",
    "    malignant_count += 1\n",
    "    metadata_train.append(augmented_malignant_metadata.iloc[i])\n",
    "    \n",
    "augmented_malignant_hdf5.close()\n",
    "print(\"Loaded augmented malignant images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5be58e",
   "metadata": {},
   "source": [
    "## Add ISIC malignant data to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a82feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_metadata_path = 'isic_metadata.csv'\n",
    "isic_hdf5_path = 'isic_image.hdf5'\n",
    "isic_metadata = pd.read_csv(isic_metadata_path,low_memory=False)\n",
    "isic_hdf5 = h5py.File(isic_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0569ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81722/81722 [01:00<00:00, 1352.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ISIC malignant images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(isic_metadata))):\n",
    "    if isic_metadata.iloc[i]['benign_malignant'] != 'malignant': \n",
    "        continue\n",
    "    image_id = isic_metadata.iloc[i]['isic_id']\n",
    "    image = isic_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    X_train.append(image)\n",
    "    y_train.append(1)\n",
    "    malignant_count += 1\n",
    "    metadata_train.append(isic_metadata.iloc[i])\n",
    "isic_hdf5.close()\n",
    "print(\"Loaded ISIC malignant images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d641af1",
   "metadata": {},
   "source": [
    "## Add the Augmented ISIC data into training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06cb11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_augmented_data_path = \"isic_augmented_data.hdf5\"\n",
    "isic_augmented_metadata_path = \"isic_augmented_metadata.csv\"\n",
    "isic_augmented_metadata = pd.read_csv(isic_augmented_metadata_path, low_memory=False)\n",
    "isic_augmented_hdf5 = h5py.File(isic_augmented_data_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9768fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46195/46195 [01:13<00:00, 627.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ISIC augmented malignant images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(isic_augmented_metadata))):\n",
    "    image_id = f\"{isic_augmented_metadata.iloc[i]['isic_id']}\"\n",
    "    image = isic_augmented_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    X_train.append(image)\n",
    "    y_train.append(1)\n",
    "    malignant_count += 1\n",
    "    metadata_train.append(isic_augmented_metadata.iloc[i])\n",
    "isic_augmented_hdf5.close()\n",
    "print(\"Loaded ISIC augmented malignant images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c32f11e",
   "metadata": {},
   "source": [
    "## Balance the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bab05fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train before balancing: 298034\n",
      "malignant count: 57792\n",
      "benign count: 400666\n",
      "malignant ratio: 0.19391076185938516\n"
     ]
    }
   ],
   "source": [
    "# balance X_train and y_train so that they have the same number of benign and malignant samples\n",
    "print(f'Length of X_train before balancing: {len(X_train)}')\n",
    "print(f'malignant count: {malignant_count}')\n",
    "print(f'benign count: {benign_count}')\n",
    "print(f'malignant ratio: {malignant_count/len(X_train)}')\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "# metadata_train = pd.DataFrame(metadata_train)\n",
    "\n",
    "# malignant_indices = np.where(y_train == 1)[0]\n",
    "# print(f'there are {len(malignant_indices)} malignant samples')\n",
    "# benign_indices = np.where(y_train == 0)[0]\n",
    "# print(f'there are {len(benign_indices)} benign samples')\n",
    "# benign_indices = np.random.choice(benign_indices, len(malignant_indices), replace=False)\n",
    "# balanced_indices = np.concatenate([malignant_indices, benign_indices])\n",
    "# np.random.shuffle(balanced_indices)\n",
    "# X_train = X_train[balanced_indices]\n",
    "# y_train = y_train[balanced_indices]\n",
    "# metadata_train = metadata_train.iloc[balanced_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "385d384e-0605-4008-a2c6-988c0c2ec895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 298034\n",
      "Validation data: 60159\n",
      "Test data: 100265\n",
      "Metadata Training data: 298034\n",
      "Metadata Validation data: 60159\n",
      "Metadata Test data: 100265\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data: {len(X_train)}')\n",
    "print(f'Validation data: {len(X_val)}')\n",
    "print(f'Test data: {len(X_test)}')\n",
    "print(f'Metadata Training data: {len(metadata_train)}')\n",
    "print(f'Metadata Validation data: {len(metadata_val)}')\n",
    "print(f'Metadata Test data: {len(metadata_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78d322",
   "metadata": {},
   "source": [
    "## Load CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c34365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b756755",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc2dff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pos_weight criterion: tensor([6.9329], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from ModelTrainer import Trainer\n",
    "densenet_weights = DenseNet121_Weights.DEFAULT\n",
    "densenet_transform = densenet_weights.transforms()\n",
    "densenet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=densenet_transform)\n",
    "densenet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=densenet_transform)\n",
    "densenet_model = densenet121(weights=densenet_weights)\n",
    "lr = 1e-5\n",
    "num_epochs = 20\n",
    "dense_net_trainer = Trainer(device, densenet_train_dataset, densenet_val_dataset, \"DenseNet121\", densenet_weights, densenet_transform, densenet_model, malignant_count, benign_count, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247174f-cfff-4084-b71f-f95c879a1818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/4657 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "dense_net_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea77a71",
   "metadata": {},
   "source": [
    "### Load model if already trained and calculate pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet_model_path = \"DenseNet121_checkpoints/DenseNet121_epoch_20.pth\"\n",
    "# densenet_checkpoint = torch.load(densenet_model_path, weights_only=False, map_location=device)\n",
    "# dense_net_trainer.model.load_state_dict(densenet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f6b59",
   "metadata": {},
   "source": [
    "### Calculate test pAUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc_pauc import pAUC\n",
    "dense_net_trainer.model.eval()\n",
    "calc_pAUC = pAUC(device, dense_net_trainer.model, dense_net_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()\n",
    "print(f\"pAUC for densenet: {calc_pAUC.pAUC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe25088-416d-456f-b84d-77a9ca36d32c",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914910f-00ef-48d5-b255-de089719c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "efficientnet_weights = EfficientNet_B3_Weights.DEFAULT\n",
    "efficientnet_transform = efficientnet_weights.transforms()\n",
    "efficientnet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=efficientnet_transform)\n",
    "efficientnet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=efficientnet_transform)\n",
    "efficientnet_model = efficientnet_b3(weights=efficientnet_weights)\n",
    "lr = 3e-5\n",
    "num_epochs = 20\n",
    "efficientnet_trainer = Trainer(device, efficientnet_train_dataset, efficientnet_val_dataset, \"EfficientNet-B3\", efficientnet_weights, efficientnet_transform, efficientnet_model, malignant_count, benign_count, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1ab4b",
   "metadata": {},
   "source": [
    "### Load EfficientNet Model if already trained and compute pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad971031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet_model_path = \"EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_18.pth\"\n",
    "# efficientnet_checkpoint = torch.load(efficientnet_model_path, weights_only=False, map_location=device)\n",
    "# efficientnet_model.load_state_dict(efficientnet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac052bd",
   "metadata": {},
   "source": [
    "### pAUC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ecc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model.eval()\n",
    "calc_pAUC = pAUC(device, efficientnet_trainer.model, efficientnet_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()\n",
    "print(f\"pAUC for efficientnet: {calc_pAUC.pAUC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb181cd5",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5018a24-9c63-474d-9db9-eb72ac9b43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "resnet_weights = ResNet50_Weights.DEFAULT\n",
    "resnet_transform = resnet_weights.transforms()\n",
    "\n",
    "resnet_train_dataset = HDF5Dataset(X_train, y_train, transform=resnet_transform)\n",
    "resnet_val_dataset = HDF5Dataset(X_val, y_val, transform=resnet_transform)\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 1)\n",
    "\n",
    "lr = 4e-5\n",
    "num_epochs = 20\n",
    "resnet_trainer = Trainer(device, resnet_train_dataset, resnet_val_dataset, \"ResNet50\", resnet_weights, resnet_transform, resnet_model, malignant_count, benign_count, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779821f",
   "metadata": {},
   "source": [
    "### Load ResNet50 if already trained and calculate pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de725b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_model_path = \"ResNet50_checkpoints/ResNet50_epoch_20.pth\"\n",
    "# resnet_checkpoint = torch.load(resnet_model_path, weights_only=False, map_location=device)\n",
    "# resnet_trainer.model.load_state_dict(resnet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8cd26a",
   "metadata": {},
   "source": [
    "### pAUC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.eval()\n",
    "calc_pAUC = pAUC(device, resnet_trainer.model, resnet_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()\n",
    "print(f\"pAUC for resnet: {calc_pAUC.pAUC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e9a13",
   "metadata": {},
   "source": [
    "## Output predictions for train/val/test for all CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75e45a-208b-4927-89b3-aa0146aa1259",
   "metadata": {},
   "source": [
    "#### Convert CNNs's output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768adf28-0940-439f-88ef-52c3d0f4ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "class TorchCNNWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device='cpu', transform=None, threshold=0.5):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _prepare_image(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            if img.dtype != np.uint8:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "        return self.transform(img).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        probs = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for img in tqdm(X, desc=\"Predicting with CNN\"):\n",
    "                img_tensor = self._prepare_image(img)\n",
    "                logits = self.model(img_tensor)\n",
    "                prob = torch.sigmoid(logits).cpu().item()\n",
    "                probs.append(prob)\n",
    "                # probs.append([1 - prob, prob])\n",
    "    \n",
    "        return probs\n",
    "\n",
    "    # def predict(self, X):\n",
    "    #     probs = self.predict_proba(X)\n",
    "        \n",
    "    #     # return (probs[:, 1] >= self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ad03d-de31-4855-aa3c-196cc044e568",
   "metadata": {},
   "source": [
    "### Convert model into essemble model compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4e945-cab7-47f0-97fe-4291ac49c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_wrapper = TorchCNNWrapper(\n",
    "    model=dense_net_trainer.model,\n",
    "    device=device,\n",
    "    transform=dense_net_trainer.transform\n",
    ")\n",
    "\n",
    "efficientnet_wrapper = TorchCNNWrapper(\n",
    "    model=efficientnet_trainer.model,\n",
    "    device=device,\n",
    "    transform=efficientnet_trainer.transform\n",
    ")\n",
    "\n",
    "resnet_wrapper = TorchCNNWrapper(\n",
    "    model=resnet_trainer.model,\n",
    "    device=device,\n",
    "    transform=resnet_trainer.transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4da3d-9613-4616-a622-f2f4ca4ee506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for training set\n",
    "densenet_train_preds = densenet_wrapper.predict_proba(X_train)\n",
    "efficientnet_train_preds = efficientnet_wrapper.predict_proba(X_train)\n",
    "resnet_train_preds = resnet_wrapper.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for validation set\n",
    "densenet_val_preds = densenet_wrapper.predict_proba(X_val)\n",
    "efficientnet_val_preds = efficientnet_wrapper.predict_proba(X_val)\n",
    "resnet_val_preds = resnet_wrapper.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dff358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for test set\n",
    "densenet_test_preds = densenet_wrapper.predict_proba(X_test)\n",
    "efficientnet_test_preds = efficientnet_wrapper.predict_proba(X_test)\n",
    "resnet_test_preds = resnet_wrapper.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train predictions\n",
    "train_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_train], name=\"isic_id\"),\n",
    "    pd.Series(densenet_train_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_train_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_train_preds, name=\"resnet\"),\n",
    "    pd.Series(y_train, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd concat to combine the predictions\n",
    "val_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_val], name=\"isic_id\"),\n",
    "    pd.Series(densenet_val_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_val_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_val_preds, name=\"resnet\"),\n",
    "    pd.Series(y_val, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd concat to combine the predictions\n",
    "test_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_test], name=\"isic_id\"),\n",
    "    pd.Series(densenet_test_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_test_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_test_preds, name=\"resnet\"),\n",
    "    pd.Series(y_test, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50455eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.to_csv(\"train_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to csv\n",
    "val_preds.to_csv(\"val_predictions.csv\", index=False)\n",
    "test_preds.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489439a3",
   "metadata": {},
   "source": [
    "## Load Tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1870b68",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f1315-44d5-45a4-b420-989fbd8e911a",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4407d2-c9ad-470a-bbbf-ee5db2469f8c",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
