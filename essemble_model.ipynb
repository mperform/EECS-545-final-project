{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c96576d",
   "metadata": {},
   "source": [
    "# Assemble Model using DenseNet, EfficientNet, ResNet50, XGBoost, Light GBM, and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0552969-dff4-4a3e-9bb9-361925f9e4c4",
   "metadata": {},
   "source": [
    "## Here's datasets you will need\n",
    "- train-image.hdf5\n",
    "- train-metadata.csv\n",
    "- augmented_data.hdf5\n",
    "- augmented_metadata.csv\n",
    "- isic_image.hdf5\n",
    "- isic_metadata.csv\n",
    "- test-image.hdf5\n",
    "- test-metadata.csv\n",
    "## Here's the models/paths you need to run without training the CNN model\n",
    "- DenseNet121_checkpoints/DenseNet121_epoch_20.pth\n",
    "- EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\n",
    "- ResNet50_checkpoints/ResNet50_epoch_20.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb04e90",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dd2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "# from dataset import HDF5Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from isic_metric import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863765d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0a64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "metadata = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a898a1d",
   "metadata": {},
   "source": [
    "### First, load all data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7f05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_hdf5_path = 'train-image.hdf5'\n",
    "original_train_metadata_path = 'train-metadata.csv'\n",
    "original_train_metadata = pd.read_csv(original_train_metadata_path,low_memory=False)   \n",
    "original_train_hdf5 = h5py.File(original_train_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31be5557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401059/401059 [05:37<00:00, 1189.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(original_train_metadata))):\n",
    "    if original_train_metadata.iloc[i]['target'] == 0: \n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "    image_id = original_train_metadata.iloc[i]['isic_id']\n",
    "    image = original_train_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    images.append(image)\n",
    "    metadata.append(original_train_metadata.iloc[i])\n",
    "    \n",
    "# original_train_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c9664",
   "metadata": {},
   "source": [
    "### Second, load the augmented malignant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e157a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_malignant_hdf5_path = 'augmented_data.hdf5'\n",
    "augmented_malignant_metadata_path = 'augmented_metadata.csv'\n",
    "augmented_malignant_metadata = pd.read_csv(augmented_malignant_metadata_path,low_memory=False)\n",
    "augmented_malignant_hdf5 = h5py.File(augmented_malignant_hdf5_path, 'r')\n",
    "n_augmentations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(augmented_malignant_metadata))):\n",
    "\n",
    "    image_id = f\"{augmented_malignant_metadata.iloc[i]['isic_id']}\"\n",
    "    image = augmented_malignant_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    images.append(image)\n",
    "    labels.append(1)\n",
    "    metadata.append(augmented_malignant_metadata.iloc[i])\n",
    "    \n",
    "augmented_malignant_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5be58e",
   "metadata": {},
   "source": [
    "### Third, load the ISIC full database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a82feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_metadata_path = 'isic_metadata.csv'\n",
    "isic_hdf5_path = 'isic_image.hdf5'\n",
    "isic_metadata = pd.read_csv(isic_metadata_path,low_memory=False)\n",
    "isic_hdf5 = h5py.File(isic_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(isic_metadata))):\n",
    "    if isic_metadata.iloc[i]['benign_malignant'] == 'malignant': \n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "    image_id = isic_metadata.iloc[i]['isic_id']\n",
    "    image = isic_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    images.append(image)\n",
    "    metadata.append(isic_metadata.iloc[i])\n",
    "isic_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a93fb",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a373bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HDF5Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 40% train, 10% val, 50% test split\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    images, labels, test_size=0.5, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "metadata_temp, metadata_test = train_test_split(\n",
    "    metadata, test_size=0.5, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "metadata_train, metadata_val = train_test_split(\n",
    "    metadata_temp, test_size=0.2, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d384e-0605-4008-a2c6-988c0c2ec895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training data: {len(X_train)}')\n",
    "print(f'Validation data: {len(X_val)}')\n",
    "print(f'Test data: {len(X_test)}')\n",
    "print(f'Metadata Training data: {len(metadata_train)}')\n",
    "print(f'Metadata Validation data: {len(metadata_val)}')\n",
    "print(f'Metadata Test data: {len(metadata_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4938933",
   "metadata": {},
   "source": [
    "### Load ISIC Competition Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isic_test_metadata_path = 'test-metadata.csv'\n",
    "# isic_test_metadata = pd.read_csv(isic_test_metadata_path,low_memory=False)\n",
    "# isic_test_hdf5_path = 'test-image.hdf5'\n",
    "# isic_test_hdf5 = h5py.File(isic_test_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ba078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# X_test_isic = []\n",
    "# X_test_isic_id = []\n",
    "# metadata_test_isic = []\n",
    "# for i in tqdm(range(len(isic_test_metadata))):\n",
    "#     image_id = isic_test_metadata.iloc[i]['isic_id']\n",
    "#     image = isic_test_hdf5[image_id][()]\n",
    "#     image = np.frombuffer(image, dtype=np.uint8)\n",
    "#     image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "#     image = cv2.resize(image, (128, 128))\n",
    "#     image = image / 255\n",
    "    \n",
    "#     # since it does not have labels, we need to manualy ensure it works with the models\n",
    "#     if isinstance(image, np.ndarray):\n",
    "#         # First ensure it's uint8\n",
    "#         if image.dtype != np.uint8:\n",
    "#             image = (image * 255).astype(np.uint8)\n",
    "#         image = Image.fromarray(image)\n",
    "#     X_test_isic.append(image)\n",
    "#     metadata_test_isic.append(isic_test_metadata.iloc[i])\n",
    "#     X_test_isic_id.append(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970600f4",
   "metadata": {},
   "source": [
    "## Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6851d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle training set imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78d322",
   "metadata": {},
   "source": [
    "## Load CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b756755",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from ModelTrainer import Trainer\n",
    "densenet_weights = DenseNet121_Weights.DEFAULT\n",
    "densenet_transform = densenet_weights.transforms()\n",
    "densenet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=densenet_transform)\n",
    "densenet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=densenet_transform)\n",
    "densenet_model = densenet121(weights=densenet_weights)\n",
    "lr = 1e-4\n",
    "num_epochs = 20\n",
    "dense_net_trainer = Trainer(device, densenet_train_dataset, densenet_val_dataset, \"DenseNet121\", densenet_weights, densenet_transform, densenet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247174f-cfff-4084-b71f-f95c879a1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea77a71",
   "metadata": {},
   "source": [
    "### Load model if already trained and calculate pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model_path = \"DenseNet121_checkpoints/DenseNet121_epoch_20.pth\"\n",
    "densenet_checkpoint = torch.load(densenet_model_path, weights_only=False, map_location=device)\n",
    "dense_net_trainer.model.load_state_dict(densenet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f6b59",
   "metadata": {},
   "source": [
    "### Calculate test pAUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc_pauc import pAUC\n",
    "dense_net_trainer.model.eval()\n",
    "calc_pAUC = pAUC(device, dense_net_trainer.model, dense_net_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe25088-416d-456f-b84d-77a9ca36d32c",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914910f-00ef-48d5-b255-de089719c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "efficientnet_weights = EfficientNet_B3_Weights.DEFAULT\n",
    "efficientnet_transform = efficientnet_weights.transforms()\n",
    "efficientnet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=efficientnet_transform)\n",
    "efficientnet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=efficientnet_transform)\n",
    "efficientnet_model = efficientnet_b3(weights=efficientnet_weights)\n",
    "lr = 3e-5\n",
    "num_epochs = 20\n",
    "efficientnet_trainer = Trainer(device, efficientnet_train_dataset, efficientnet_val_dataset, \"EfficientNet-B3\", efficientnet_weights, efficientnet_transform, efficientnet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1ab4b",
   "metadata": {},
   "source": [
    "### Load EfficientNet Model if already trained and compute pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad971031",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model_path = \"EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\"\n",
    "efficientnet_checkpoint = torch.load(efficientnet_model_path, weights_only=False, map_location=device)\n",
    "efficientnet_model.load_state_dict(efficientnet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac052bd",
   "metadata": {},
   "source": [
    "### pAUC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ecc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model.eval()\n",
    "calc_pAUC = pAUC(device, efficientnet_trainer.model, efficientnet_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb181cd5",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5018a24-9c63-474d-9db9-eb72ac9b43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "resnet_weights = ResNet50_Weights.DEFAULT\n",
    "resnet_transform = resnet_weights.transforms()\n",
    "\n",
    "resnet_train_dataset = HDF5Dataset(X_train, y_train, transform=resnet_transform)\n",
    "resnet_val_dataset = HDF5Dataset(X_val, y_val, transform=resnet_transform)\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 1)\n",
    "\n",
    "lr = 4e-5\n",
    "num_epochs = 20\n",
    "resnet_trainer = Trainer(device, resnet_train_dataset, resnet_val_dataset, \"ResNet50\", resnet_weights, resnet_transform, resnet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779821f",
   "metadata": {},
   "source": [
    "### Load ResNet50 if already trained and calculate pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de725b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_path = \"ResNet50_checkpoints/ResNet50_epoch_20.pth\"\n",
    "resnet_checkpoint = torch.load(resnet_model_path, weights_only=False, map_location=device)\n",
    "resnet_trainer.model.load_state_dict(resnet_checkpoint['model_state_dict'])\n",
    "# resnet_model.eval()\n",
    "# calc_pAUC = pAUC(device, resnet_model, resnet_transform, X_test, y_test,  metadata_test)\n",
    "# calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8cd26a",
   "metadata": {},
   "source": [
    "### pAUC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.eval()\n",
    "calc_pAUC = pAUC(device, resnet_trainer.model, resnet_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e9a13",
   "metadata": {},
   "source": [
    "## Output predictions for train/val/test for all CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75e45a-208b-4927-89b3-aa0146aa1259",
   "metadata": {},
   "source": [
    "#### Convert CNNs's output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768adf28-0940-439f-88ef-52c3d0f4ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "class TorchCNNWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device='cpu', transform=None, threshold=0.5):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _prepare_image(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            if img.dtype != np.uint8:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "        return self.transform(img).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        probs = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for img in tqdm(X, desc=\"Predicting with CNN\"):\n",
    "                img_tensor = self._prepare_image(img)\n",
    "                logits = self.model(img_tensor)\n",
    "                prob = torch.sigmoid(logits).cpu().item()\n",
    "                probs.append(prob)\n",
    "                # probs.append([1 - prob, prob])\n",
    "    \n",
    "        return probs\n",
    "\n",
    "    # def predict(self, X):\n",
    "    #     probs = self.predict_proba(X)\n",
    "        \n",
    "    #     # return (probs[:, 1] >= self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ad03d-de31-4855-aa3c-196cc044e568",
   "metadata": {},
   "source": [
    "### Convert model into essemble model compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4e945-cab7-47f0-97fe-4291ac49c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_wrapper = TorchCNNWrapper(\n",
    "    model=dense_net_trainer.model,\n",
    "    device=device,\n",
    "    transform=dense_net_trainer.transform\n",
    ")\n",
    "\n",
    "efficientnet_wrapper = TorchCNNWrapper(\n",
    "    model=efficientnet_trainer.model,\n",
    "    device=device,\n",
    "    transform=efficientnet_trainer.transform\n",
    ")\n",
    "\n",
    "resnet_wrapper = TorchCNNWrapper(\n",
    "    model=resnet_trainer.model,\n",
    "    device=device,\n",
    "    transform=resnet_trainer.transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4da3d-9613-4616-a622-f2f4ca4ee506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for training set\n",
    "densenet_train_preds = densenet_wrapper.predict_proba(X_train)\n",
    "efficientnet_train_preds = efficientnet_wrapper.predict_proba(X_train)\n",
    "resnet_train_preds = resnet_wrapper.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for validation set\n",
    "densenet_val_preds = densenet_wrapper.predict_proba(X_val)\n",
    "efficientnet_val_preds = efficientnet_wrapper.predict_proba(X_val)\n",
    "resnet_val_preds = resnet_wrapper.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dff358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for test set\n",
    "densenet_test_preds = densenet_wrapper.predict_proba(X_test)\n",
    "efficientnet_test_preds = efficientnet_wrapper.predict_proba(X_test)\n",
    "resnet_test_preds = resnet_wrapper.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train predictions\n",
    "train_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_train], name=\"isic_id\"),\n",
    "    pd.Series(densenet_train_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_train_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_train_preds, name=\"resnet\"),\n",
    "    pd.Series(y_train, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd concat to combine the predictions\n",
    "val_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_val], name=\"isic_id\"),\n",
    "    pd.Series(densenet_val_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_val_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_val_preds, name=\"resnet\"),\n",
    "    pd.Series(y_val, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd concat to combine the predictions\n",
    "test_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_test], name=\"isic_id\"),\n",
    "    pd.Series(densenet_test_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_test_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_test_preds, name=\"resnet\"),\n",
    "    pd.Series(y_test, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50455eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.to_csv(\"train_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to csv\n",
    "val_preds.to_csv(\"val_predictions.csv\", index=False)\n",
    "test_preds.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489439a3",
   "metadata": {},
   "source": [
    "## Load Tree based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47de2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1870b68",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f1315-44d5-45a4-b420-989fbd8e911a",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4407d2-c9ad-470a-bbbf-ee5db2469f8c",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
