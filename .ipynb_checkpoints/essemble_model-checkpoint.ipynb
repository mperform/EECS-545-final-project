{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c96576d",
   "metadata": {},
   "source": [
    "# Assemble Model using DenseNet, EfficientNet, ResNet50, XGBoost, Light GBM, and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0552969-dff4-4a3e-9bb9-361925f9e4c4",
   "metadata": {},
   "source": [
    "## Here's datasets you will need\n",
    "- train-image.hdf5\n",
    "- train-metadata.csv\n",
    "- augmented_data.hdf5\n",
    "- augmented_metadata.csv\n",
    "- isic_image.hdf5\n",
    "- isic_metadata.csv\n",
    "- test-image.hdf5\n",
    "- test-metadata.csv\n",
    "## Here's the models/paths you need to run without training the CNN model\n",
    "- DenseNet121_checkpoints/DenseNet121_epoch_20.pth\n",
    "- EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\n",
    "- ResNet50_checkpoints/ResNet50_epoch_20.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb04e90",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dd2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from dataset import HDF5Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from isic_metric import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863765d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0a64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "metadata = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a898a1d",
   "metadata": {},
   "source": [
    "### First, load all data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7f05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_hdf5_path = 'train-image.hdf5'\n",
    "original_train_metadata_path = 'train-metadata.csv'\n",
    "original_train_metadata = pd.read_csv(original_train_metadata_path,low_memory=False)   \n",
    "original_train_hdf5 = h5py.File(original_train_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31be5557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401059/401059 [05:33<00:00, 1203.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(original_train_metadata))):\n",
    "    if original_train_metadata.iloc[i]['target'] == 0: \n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "    image_id = original_train_metadata.iloc[i]['isic_id']\n",
    "    image = original_train_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    images.append(image)\n",
    "    metadata.append(original_train_metadata.iloc[i])\n",
    "    \n",
    "# original_train_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989ac7f",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3675c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60% training, 15% validation, 25% testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.625, random_state=42)  # 0.625 * 0.4 = 0.25\n",
    "\n",
    "# split metadata\n",
    "metadata_train, metadata_temp = train_test_split(metadata, test_size=0.4, random_state=42)\n",
    "metadata_val, metadata_test = train_test_split(metadata_temp, test_size=0.625, random_state=42)  # 0.625 * 0.4 = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26e478",
   "metadata": {},
   "source": [
    "## Add Augmented malignant images to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e157a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_malignant_hdf5_path = 'augmented_data.hdf5'\n",
    "augmented_malignant_metadata_path = 'augmented_metadata.csv'\n",
    "augmented_malignant_metadata = pd.read_csv(augmented_malignant_metadata_path,low_memory=False)\n",
    "augmented_malignant_hdf5 = h5py.File(augmented_malignant_hdf5_path, 'r')\n",
    "n_augmentations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d51fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1965/1965 [00:02<00:00, 928.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(augmented_malignant_metadata))):\n",
    "    image_id = f\"{augmented_malignant_metadata.iloc[i]['isic_id']}\"\n",
    "    image = augmented_malignant_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    X_train.append(image)\n",
    "    y_train.append(1)\n",
    "    metadata_train.append(augmented_malignant_metadata.iloc[i])\n",
    "    \n",
    "augmented_malignant_hdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0599423-c6ab-4f7e-9a53-2fdaeb35e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242600\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5be58e",
   "metadata": {},
   "source": [
    "## Add ISIC malignant data to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a82feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_metadata_path = 'isic_metadata.csv'\n",
    "isic_hdf5_path = 'isic_image.hdf5'\n",
    "isic_metadata = pd.read_csv(isic_metadata_path,low_memory=False)\n",
    "isic_hdf5 = h5py.File(isic_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0569ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81722/81722 [00:26<00:00, 3057.51it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(isic_metadata))):\n",
    "    if isic_metadata.iloc[i]['benign_malignant'] != 'malignant': \n",
    "        continue\n",
    "    image_id = isic_metadata.iloc[i]['isic_id']\n",
    "    image = isic_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    X_train.append(image)\n",
    "    y_train.append(1)\n",
    "    metadata_train.append(isic_metadata.iloc[i])\n",
    "isic_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c32f11e",
   "metadata": {},
   "source": [
    "## Balance the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bab05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance X_train and y_train so that they have the same number of benign and malignant samples\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "metadata_train = pd.DataFrame(metadata_train)\n",
    "\n",
    "malignant_indices = np.where(y_train == 1)[0]\n",
    "benign_indices = np.where(y_train == 0)[0]\n",
    "benign_indices = np.random.choice(benign_indices, len(malignant_indices), replace=False)\n",
    "balanced_indices = np.concatenate([malignant_indices, benign_indices])\n",
    "np.random.shuffle(balanced_indices)\n",
    "X_train = X_train[balanced_indices]\n",
    "y_train = y_train[balanced_indices]\n",
    "metadata_train = metadata_train.iloc[balanced_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "385d384e-0605-4008-a2c6-988c0c2ec895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 22854\n",
      "Validation data: 60159\n",
      "Test data: 100265\n",
      "Metadata Training data: 22854\n",
      "Metadata Validation data: 60159\n",
      "Metadata Test data: 100265\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data: {len(X_train)}')\n",
    "print(f'Validation data: {len(X_val)}')\n",
    "print(f'Test data: {len(X_test)}')\n",
    "print(f'Metadata Training data: {len(metadata_train)}')\n",
    "print(f'Metadata Validation data: {len(metadata_val)}')\n",
    "print(f'Metadata Test data: {len(metadata_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78d322",
   "metadata": {},
   "source": [
    "## Load CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c34365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b756755",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcc2dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from ModelTrainer import Trainer\n",
    "densenet_weights = DenseNet121_Weights.DEFAULT\n",
    "densenet_transform = densenet_weights.transforms()\n",
    "densenet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=densenet_transform)\n",
    "densenet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=densenet_transform)\n",
    "densenet_model = densenet121(weights=densenet_weights)\n",
    "lr = 1e-5\n",
    "num_epochs = 20\n",
    "dense_net_trainer = Trainer(device, densenet_train_dataset, densenet_val_dataset, \"DenseNet121\", densenet_weights, densenet_transform, densenet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247174f-cfff-4084-b71f-f95c879a1818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 358/358 [01:22<00:00,  4.36it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:50<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Acc = 0.9915, Precision = 0.0308, Recall = 0.2778, F1 = 0.0555, pAUC = 0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 358/358 [01:20<00:00,  4.43it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:31<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Acc = 0.9950, Precision = 0.0446, Recall = 0.2222, F1 = 0.0743, pAUC = 0.1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 358/358 [01:20<00:00,  4.42it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:31<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Acc = 0.9968, Precision = 0.0683, Recall = 0.2037, F1 = 0.1023, pAUC = 0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 358/358 [01:20<00:00,  4.43it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:31<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Acc = 0.9870, Precision = 0.0222, Recall = 0.3148, F1 = 0.0415, pAUC = 0.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 358/358 [01:20<00:00,  4.43it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:32<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Acc = 0.9956, Precision = 0.0517, Recall = 0.2222, F1 = 0.0839, pAUC = 0.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 358/358 [01:20<00:00,  4.47it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:32<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Acc = 0.9930, Precision = 0.0356, Recall = 0.2593, F1 = 0.0626, pAUC = 0.0918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 358/358 [01:20<00:00,  4.46it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:32<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Acc = 0.9968, Precision = 0.0629, Recall = 0.1852, F1 = 0.0939, pAUC = 0.0914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 358/358 [01:20<00:00,  4.45it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:32<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Acc = 0.9929, Precision = 0.0461, Recall = 0.3519, F1 = 0.0815, pAUC = 0.1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 358/358 [01:20<00:00,  4.46it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:31<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Acc = 0.9885, Precision = 0.0296, Recall = 0.3704, F1 = 0.0548, pAUC = 0.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 358/358 [01:20<00:00,  4.47it/s]\n",
      "Validation: 100%|██████████| 940/940 [02:32<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Acc = 0.9936, Precision = 0.0418, Recall = 0.2778, F1 = 0.0726, pAUC = 0.0956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20:  54%|█████▍    | 195/358 [00:43<00:33,  4.81it/s]"
     ]
    }
   ],
   "source": [
    "dense_net_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea77a71",
   "metadata": {},
   "source": [
    "### Load model if already trained and calculate pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet_model_path = \"DenseNet121_checkpoints/DenseNet121_epoch_20.pth\"\n",
    "# densenet_checkpoint = torch.load(densenet_model_path, weights_only=False, map_location=device)\n",
    "# dense_net_trainer.model.load_state_dict(densenet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f6b59",
   "metadata": {},
   "source": [
    "### Calculate test pAUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc_pauc import pAUC\n",
    "dense_net_trainer.model.eval()\n",
    "calc_pAUC = pAUC(device, dense_net_trainer.model, dense_net_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe25088-416d-456f-b84d-77a9ca36d32c",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914910f-00ef-48d5-b255-de089719c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "efficientnet_weights = EfficientNet_B3_Weights.DEFAULT\n",
    "efficientnet_transform = efficientnet_weights.transforms()\n",
    "efficientnet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=efficientnet_transform)\n",
    "efficientnet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=efficientnet_transform)\n",
    "efficientnet_model = efficientnet_b3(weights=efficientnet_weights)\n",
    "lr = 3e-5\n",
    "num_epochs = 20\n",
    "efficientnet_trainer = Trainer(device, efficientnet_train_dataset, efficientnet_val_dataset, \"EfficientNet-B3\", efficientnet_weights, efficientnet_transform, efficientnet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1ab4b",
   "metadata": {},
   "source": [
    "### Load EfficientNet Model if already trained and compute pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad971031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet_model_path = \"EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\"\n",
    "# efficientnet_checkpoint = torch.load(efficientnet_model_path, weights_only=False, map_location=device)\n",
    "# efficientnet_model.load_state_dict(efficientnet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac052bd",
   "metadata": {},
   "source": [
    "### pAUC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ecc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model.eval()\n",
    "calc_pAUC = pAUC(device, efficientnet_trainer.model, efficientnet_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb181cd5",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5018a24-9c63-474d-9db9-eb72ac9b43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "resnet_weights = ResNet50_Weights.DEFAULT\n",
    "resnet_transform = resnet_weights.transforms()\n",
    "\n",
    "resnet_train_dataset = HDF5Dataset(X_train, y_train, transform=resnet_transform)\n",
    "resnet_val_dataset = HDF5Dataset(X_val, y_val, transform=resnet_transform)\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 1)\n",
    "\n",
    "lr = 4e-5\n",
    "num_epochs = 20\n",
    "resnet_trainer = Trainer(device, resnet_train_dataset, resnet_val_dataset, \"ResNet50\", resnet_weights, resnet_transform, resnet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779821f",
   "metadata": {},
   "source": [
    "### Load ResNet50 if already trained and calculate pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de725b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_model_path = \"ResNet50_checkpoints/ResNet50_epoch_20.pth\"\n",
    "# resnet_checkpoint = torch.load(resnet_model_path, weights_only=False, map_location=device)\n",
    "# resnet_trainer.model.load_state_dict(resnet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8cd26a",
   "metadata": {},
   "source": [
    "### pAUC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.eval()\n",
    "calc_pAUC = pAUC(device, resnet_trainer.model, resnet_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e9a13",
   "metadata": {},
   "source": [
    "## Output predictions for train/val/test for all CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75e45a-208b-4927-89b3-aa0146aa1259",
   "metadata": {},
   "source": [
    "#### Convert CNNs's output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768adf28-0940-439f-88ef-52c3d0f4ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "class TorchCNNWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device='cpu', transform=None, threshold=0.5):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _prepare_image(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            if img.dtype != np.uint8:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "        return self.transform(img).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        probs = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for img in tqdm(X, desc=\"Predicting with CNN\"):\n",
    "                img_tensor = self._prepare_image(img)\n",
    "                logits = self.model(img_tensor)\n",
    "                prob = torch.sigmoid(logits).cpu().item()\n",
    "                probs.append(prob)\n",
    "                # probs.append([1 - prob, prob])\n",
    "    \n",
    "        return probs\n",
    "\n",
    "    # def predict(self, X):\n",
    "    #     probs = self.predict_proba(X)\n",
    "        \n",
    "    #     # return (probs[:, 1] >= self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ad03d-de31-4855-aa3c-196cc044e568",
   "metadata": {},
   "source": [
    "### Convert model into essemble model compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4e945-cab7-47f0-97fe-4291ac49c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_wrapper = TorchCNNWrapper(\n",
    "    model=dense_net_trainer.model,\n",
    "    device=device,\n",
    "    transform=dense_net_trainer.transform\n",
    ")\n",
    "\n",
    "efficientnet_wrapper = TorchCNNWrapper(\n",
    "    model=efficientnet_trainer.model,\n",
    "    device=device,\n",
    "    transform=efficientnet_trainer.transform\n",
    ")\n",
    "\n",
    "resnet_wrapper = TorchCNNWrapper(\n",
    "    model=resnet_trainer.model,\n",
    "    device=device,\n",
    "    transform=resnet_trainer.transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4da3d-9613-4616-a622-f2f4ca4ee506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for training set\n",
    "densenet_train_preds = densenet_wrapper.predict_proba(X_train)\n",
    "efficientnet_train_preds = efficientnet_wrapper.predict_proba(X_train)\n",
    "resnet_train_preds = resnet_wrapper.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for validation set\n",
    "densenet_val_preds = densenet_wrapper.predict_proba(X_val)\n",
    "efficientnet_val_preds = efficientnet_wrapper.predict_proba(X_val)\n",
    "resnet_val_preds = resnet_wrapper.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dff358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for test set\n",
    "densenet_test_preds = densenet_wrapper.predict_proba(X_test)\n",
    "efficientnet_test_preds = efficientnet_wrapper.predict_proba(X_test)\n",
    "resnet_test_preds = resnet_wrapper.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train predictions\n",
    "train_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_train], name=\"isic_id\"),\n",
    "    pd.Series(densenet_train_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_train_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_train_preds, name=\"resnet\"),\n",
    "    pd.Series(y_train, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd concat to combine the predictions\n",
    "val_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_val], name=\"isic_id\"),\n",
    "    pd.Series(densenet_val_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_val_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_val_preds, name=\"resnet\"),\n",
    "    pd.Series(y_val, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd concat to combine the predictions\n",
    "test_preds = pd.concat([\n",
    "    pd.Series([row['isic_id'] for row in metadata_test], name=\"isic_id\"),\n",
    "    pd.Series(densenet_test_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_test_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_test_preds, name=\"resnet\"),\n",
    "    pd.Series(y_test, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50455eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.to_csv(\"train_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to csv\n",
    "val_preds.to_csv(\"val_predictions.csv\", index=False)\n",
    "test_preds.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489439a3",
   "metadata": {},
   "source": [
    "## Load Tree based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47de2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1870b68",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f1315-44d5-45a4-b420-989fbd8e911a",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4407d2-c9ad-470a-bbbf-ee5db2469f8c",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
